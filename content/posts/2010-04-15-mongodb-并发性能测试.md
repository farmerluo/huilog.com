---
title: mongodb 并发性能测试
author: 阿辉
date: 2010-04-15T16:07:00+00:00
categories:
- Mongodb
tags:
- Mongodb
keywords:
- Mongodb
comments: true
showTags: true
showPagination: true
showSocial: false
showDate: true
showMeta: true
---
之前做的一些mongodb的测试都是在exsi的两台虚拟间做的，由于虚拟机的问题，性能很不稳定。这两天正好有两台服务器空下来了，就用来跑了一下mongodb的并发测试。

服务器软硬件配置：

服务器：Dell PowerEdge R710  

CPU: Intel Xeon E5530 2.4G X 2 

硬盘：SAS 300G X 4 建立 Raid10  

内存：16G

windows 2003 sp2 64位  

mongodb 1.40 x64 for windows 

mongodb在这台上跑，测试程序在另一台服务器上跑，两台服务器配置基本一样，除了硬盘（另一台是SAS 147G X4  Raid10）。

<!--more-->

测试程序在之前的java测试程序基础上做了修改，增加了多线性的并发测试功能，程序源代码可从下面的链接下载：

http://farmerluo.googlecode.com/files/mongotest_0.3.rar

程序用法：
```
Usage:
mysql test:
java -jar mongotest.jar < mysql > < [select | update | insert] > < rows > < host > < username > < password> 
mongo test:
java -jar mongotest.jar < mongo > < [select | update | insert] > < rows > < host >
```
由于时间关系，mysql没有来得急测试，只测试了mongodb。

后期准备再找机器在linux系统上好好的测一下mongodb和mysql的并发性能（因为我发现虽然mongodb在单用户测试的情况下性能很好，但随着并发用户的增加，性能都是往下掉的，而我跑了一次50个并发的mysql，总的吞吐量反而是往上走的，所以很有必要同时测一次mysql和mongodb的并发性能）。

先看一下测试结果，因为这里不好贴表，只能上图了：

![/wp-content/uploads/baiduhi/2d613a876e6dff1dc75cc363.jpg](/wp-content/uploads/baiduhi/2d613a876e6dff1dc75cc363.jpg)

有一点需要说明一下，因为并发数为1的时候，select很慢，跑1000万花的时间过长，所以我这边只测试了10万条记录，我看看了数据，差别并不大。

测试的总记录数都是1000万，可以看到，随着并发数的增加，mongdb的insert吞吐量掉得很快。而update稍为平稳一些，总得也在往下走的，从查询来看，随着并发的增加，吞吐量也跟着增加，符合我们的预期。

insert的时候，mongodb会创建多个数据库文件，他会先创建一个64M的文件，不够用了再创建一个128M,然后是256M,512M,1G,2G，然后就是一直2G的创建下去。

测试程序写入的记录是每条1k多一点(4 X 256字符，再加一个int，一个默认的_id)，所以1000万记录算出来差不多是10G（除了默认的索引_id,没有另外加其它索引）。而实际上，mongodb总共创建了147G的数据库文件。这样的存储容量对于想用固定硬盘的用户来说是个考验。

insert并发吞往下掉的原因，我怀疑是因为在多并发时mongodb同时操作IO有关，其实通过mongodb服务器上的监控程序我们看到，在mongodb创建1G的数据库文件之前，每秒insert有20000左右，后来就开始低了。我们知道，当写一个1G文件花的时间，总是要比同时写10个100M的文件来得要快。但是这块我想mongodb还有优化的空间,官网上也承认之前的版本并发性能并不好，所以在1.4版本上做了改进。

200并发时update反而比100并发性能要好，或许和单并发测试的数据比较少有关，在200并发时，单并发只测试了5万数据。

另外在高并发时，mongodb的稳定性和健状性也是非常值得关注的。我们在测试200并发时，跑了一段时间后，从mongodb的监控程序发现突然没有了insert的数据，然而java的测试程序也并没有报错，就一直停在那里不动。重启并做一些优化后才测试完200并发。

资源占用方面：cpu 20%上下，任务管理器内显示PF内存占用1G,但mongod进程显示占用了12G的内存做缓存使用了。

或许看线性图表更为直观一些：
![/wp-content/uploads/baiduhi/86b197dd347967035882dd63.jpg](/wp-content/uploads/baiduhi/86b197dd347967035882dd63.jpg)
![/wp-content/uploads/baiduhi/bb3d2edd02f1b6ee8c102963.jpg](/wp-content/uploads/baiduhi/bb3d2edd02f1b6ee8c102963.jpg)

另外也测试了一下大数据量的并发测试

内网测试,100线程，每线程50万记录:
```
D:dist>java -Xms256M -Xmx1024M -jar mongotest.jar mongo insert 500000 100 192.168.1.12 dbtest
Total thread:100
Total run time:10404 sec
Per-thread rows:500000
Per-thread mongo insert Result:48row/sec
Total rows:50000000
Total mongo insert Result:4805row/sec

D:dist>java -Xms256M -Xmx1024M -jar mongotest.jar mongo update 500000 100 192.168.1.12 dbtest
Total thread:100
Total run time:13103 sec
Per-thread rows:500000
Per-thread mongo update Result:38row/sec
Total rows:50000000
Total mongo update Result:3815row/sec

D:dist>java -Xms256M -Xmx1024M -jar mongotest.jar mongo select 500000 100 192.168.1.12 dbtest
Total thread:100
Total run time:1869 sec
Per-thread rows:500000
Per-thread mongo select Result:267row/sec
Total rows:50000000
Total mongo select Result:26752row/sec
```
用这个数据对比表中100并发的数据，我们发现，虽然性能也在往下掉，但相比因并发增加而下降的性能来说并不夸张，在预期范围之内。由此可见，mongodb对于大数据量来说性能还是不错的。
